\chapter{Additional Proofs}\label{sec:additional_proofs}
\textit{
  Although the following two sections are not part of my work, they were obtained as part of the research on~\cite{RNEW}.
  I consider them too important to not be added at least in the appendix even though they are in no way my direct contribution.
  I also worked extensively on the problem in~\cref{sec:rapid-mixing}, however with no significant results.
}

\section{Convergence of the General MCMC~\cite{RNEW}}\label{sec:general-convergence}
The underlying Markov Chain of \cref{algo:sampler} is defined on the state space \constates.
In the proof of \cref{thm:sampler_is_uniform}, we assumed that $\wInt$ is countable and that we can assign a non-zero probability to every value in $\wInt$, \ie $\frac{1}{|\wInt|}$.
However, if $\wInt$ is uncountable, \eg we have real-valued $\wInt = [a,b]$, the state space \cstates might also be uncountable and the proof of \cref{thm:sampler_is_uniform} does not apply.
Not only that but also the notions of aperiodicity and irreducibility do not apply to such a Markov Chain.
For that, we need similar but more general definitions.
We thus assume for the remainder of this section that $\wInt$ consists of an arbitrary finite union of intervals.

A Markov Chain on a measureable set $\mathcal{X}$ is defined by transition probabilities $P(x, dy)$ where for each $x \in \mathcal{X}$ and measureable subset $A \subseteq \mathcal{X}$, the value $P(x, A)$ is the probability to move from $x$ to somewhere in $A$.
We again denote $i$ steps of the Markov Chain by $P^{(i)}$.
Starting with $P^{(1)}(x, dy) = P(x, dy)$, higher-order transition probabilities are then given by \[
  P^{(n + 1)}(x, A) = \int_{\mathcal{X}}P^{(n)}(x, dy)P(y, A).
\]

\begin{definition}[$\phi$-irreducibility~\cite{RobertsRosenthal04}]
  A general Markov Chain is $\phi$-irreducible if there exists a non-zero $\sigma$-finite measure $\phi$ on $\mathcal{X}$ such that for all $A \subseteq \mathcal{X}$ with $\phi(A) > 0$, and for all $x \in \mathcal{X}$, there exists a positive integer $n = n(x, A)$ such that $P^{(n)}(x, A) > 0$.
\end{definition}

\begin{definition}[Aperiodicity\cite{RobertsRosenthal04}]
  A general Markov Chain with stationary distribution $\pi({\cdot})$ is aperiodic if there do not exist $d \geq 2$ and disjoint subsets $\mathcal{X}_1,\ldots,\mathcal{X}_d \subseteq \mathcal{X}$ with $P(x, \mathcal{X}_{i + 1} = 1$ for all $x \in \mathcal{X}_i$ ($i \in [d - 1]$), and $P(x, \mathcal{X}_1) = 1$ for all $x \in \mathcal{X}_d$ such that $\pi(\mathcal{X}_1) > 0$. 
\end{definition}

\begin{theorem}[Theorem 4 of~\cite{RobertsRosenthal04}]
    \label{thm:convergence-general-mc}
    If a Markov chain on a state space with countably generated $\sigma$-algebra is $\phi$-irreducible and aperiodic and has a stationary distribution $\pi(\cdot)$, then for $\pi$-a.e. $x \in \mathcal X$,
    \[ \lim_{n \to \infty} \Vert P^n(x, \cdot) - \pi(\cdot) \Vert = 0. \]
\end{theorem}

Verifying \cref{thm:convergence-general-mc} for our proposed MC yields a proof for the general version of~\cref{thm:sampler_is_uniform}.

\begin{theorem}[Generalization of~\cref{thm:sampler_is_uniform}]
	Let $G = (V, E)$ be a directed graph and $\wInt$ a real weight interval.
	Then, the MCMC process converges to a uniform density on $\constates$.\label{thm:general-uniform}
\end{theorem}

\begin{proof}
    Subsets of $\mathbb R^m$ equipped with the standard Borel $\sigma$-algebra are countably generated by open balls with rational centers and rational radii~\cite{RobertsRosenthal04}.

    Furthermore, since the Markov chain is symmetric, detailed balance is fulfilled, \ie for probability densities $s, s'$ it holds
    \[ \pi(s)P(s, s') = \pi(s')P(s', s), \]
    for a stationary density $\pi$ and in particular for the uniform density. 
    By symmetry it holds $\int_{x \in A}P(x, B)dx = \int_{y \in B}P(y, A)dy$ for measurable $A, B \subseteq \mathcal X$ which extends to a weighting of $\pi$ when chosen as the uniform density.
    Here, stationary follows directly from detailed balance, \ie integrating over $\mathcal X$ yields
    \begin{align*}
        \int_{\mathcal X} \pi(x)P(x, y)dx &= \int_{\mathcal X} \pi(y)P(y, x)dx \\
                                          &= \pi(y)\int_{\mathcal X} P(y, x)dx \\
                                          &= \pi(y).
    \end{align*}
    
    With the existence of $\pi$, it remains to verify $\phi$-irreducibility and aperiodicity.
    Let $x \in \constates$ and $\pi(A) > 0$.
    We emulate the process of changing the weights to values exceeding some of the values of $A$ (with positive measure) to subsequently enable a move to $A$ with positive probability.
    Due to continuity there exists constant $\epsilon > 0$ where some point $y \in A$ emits $B(\epsilon, y) \subseteq A$.
    Now, with positive probability we successively change the coordinates of $x$ from smallest to largest to a value that is larger than any coordinate of any point in $B(\varepsilon, y)$ (guaranteed to exist due to continuity) and returning to a value in $B(\epsilon, y)$ after a total of $2m$ steps, yielding
    \[ P^{(2m)}(x, A) \ge P^{(2m)}(x, B(\epsilon, y)) > 0, \]
    where $\pi$ is a probability measure and as such non-zero and $\sigma$-finite.

    Suppose $\mathcal X_1$ and $\mathcal X_2$ are disjoint subsets of $\mathcal X$ both of positive $\pi$ measure and wlog.~$\mathbf{0} \in \constates \cap \mathcal X_1$, with $P(x, \mathcal X_2) = 1$ for all $x \in \mathcal X_1$. 
    This essentially represents an emigration from $\mathcal X_1$ to $\mathcal X_2$ with probability~$1$.
    Observe that in case $G$ contains at least one cycle, the probability to introduce a negative cycle is positive, hence $P(\mathbf{0}, \mathcal X_1) > 0$ leads to a contradiction as therefore $P(\mathbf{0}, \mathcal X_2) < 1$.
    
    Otherwise, since no cycles exist in $G$, the set $\constates$ coincides with $\wInt^m$ and the MCMC process degenerates to choosing uniform values in $\wInt$ and assigning them to randomly sampled edges. 
    Since $\pi(\mathcal X_1) > 0$ by definition we can find a subset $A \subset \mathcal X_1$ where for $x \in A$ it holds $P(x, \mathcal X_1) \ge P(x, A) > 0$.
\end{proof}



\section{Rapid-Mixing on the $n$-Cycle~\cite{RNEW}}\label{sec:rapid-mixing}
We showed in \cref{thm:sampler_is_uniform,thm:convergence-general-mc} that our algorithms converge to a uniform distribution over $\wInt$ and saw in \cref{sec:experiments} that in practice this happens in reasonable polynomial time.
However, we still lack a theoretical upper bound on the mixing time.
As such proofs are generally hard and very involved, we restrict ourselves to the $n$-Cycle $C_n$ and prove that our MCMC is rapidly mixing on it for a set of integer weights $\wInt = [a,b]$.

Consider an ergodic Markov chain~$M$ with state space\footnote{
    Commonly, this is denoted by $\Omega$ in existing literature as opposed to $\cstates$.    
} $\cstates$ and stationary distribution~$\pi$ (\ie the unique configuration the ergodic~$M$ converges to).
The mixing time \mixtime of~$M$ describes the smallest number of steps to reach a distribution that has at most $\epsilon$ distance from $\pi$ (in $L_1$ norm) --- even for an adversarial starting configuration.
Formally, the mixing time is defined as
$$
\mixtime = \min \Big\{ \steps \geq 0 : \max_{x \in \cstates} \Big[ \sum_{y \in \cstates} |\pi(y) - \sigma_{\steps,x}(y)| \leq \epsilon \Big] \Big\},
$$
where $\sigma_{\steps,x}$ is the distribution of states after \steps steps when starting on state $x$. 

To show rapid mixing of the Markov chain underlying \Cref{algo:sampler} for the $n$-cycle, we consider a variant that is simpler to analyze.
This chain $\mathcal{M}$ is defined as follows.
Its state space $\cstates$ is the state space of the chain underlying \Cref{algo:sampler}.
From the current state, the chain $\mathcal{M}$ transitions to the next state as follows:
\begin{itemize}
	\item With probability $1 / 2$: remain in the current state.
	\item With probability $1 / 4$: choose edge $e$ and $b \in \{-1, 1\}$ uniformly at random.
    If adding $b$ to the weight $w(e)$ yields a state in $\cstates$, move to this state.
	\item With probability $1 / 4$: choose edges $e_1$, $e_2$ uniformly at random.
    If incrementing $w(e_1)$ and decrementing $w(e_2)$ results in a state in $\cstates$, move to this state.
\end{itemize}
Since the same transitions are performed by the chain underlying \Cref{algo:sampler} with a probability bounded from below by a polynomial in $n$ and $(b - a)$, the mixing time of both chains can be related by a polynomial in $n$ and $(b - a)$ (cf. \cite[Remark 13.19]{levin2017markov}).

The main result of this section is as follows.
\begin{theorem}
	The mixing time \mixtime of the Markov chain $\mathcal{M}$ for integer weights in $[a, b]$ on the $n$-cycle satisfies
	$
	\mixtime \leq 2^{9} n^{11} b^2 (b - a) \left(\log (b - a) + \log \epsilon^{-1} \right).
	$
	\label{thm:rapid-mixing}
\end{theorem}

\noindent
We employ a common argument to show Theorem \autoref{thm:rapid-mixing}.
Let $1 = \lambda_0 > \lambda_1 \geq \dots \geq \lambda_{|\cstates|} > -1$ denote the eigenvalues of the transition matrix $P$ of $\mathcal{M}$.
Since $\mathcal{M}$ is lazy, e.g. we remain in the same state with probability at least $1 / 2$, all eigenvalues are non-negative, and it holds that $\mixtime \leq (1 - \lambda_1)^{-1} \left(\log |\cstates| + \log \epsilon^{-1} \right)$, \eg~\cite[p. 4]{sinclair1992improved}.
Thus it suffices to bound $1 - \lambda_1$ from below.

Our idea is to decompose $\mathcal{M}$ into multiple Markov chains $\mathcal{M'}$ and $\mathcal{M}_i$ where $i \in [0, nb]$.
Intuitively, $\mathcal{M'}$ moves between states that correspond to the different sums of the weights in the $n$-cycle, and each $\mathcal{M}_i$ moves between states that correspond to the same sum $i$.
Precisely, we partition $\cstates$ into the sets $\Omega_0, \dots \cstates_{nb}$ where $\cstates_i$ contains all states with a sum of weights~$i$ (n.b. since we consider a cycle graph, the sum of consistent weights is always non-negative).
We then define the chain $\mathcal{M}_i$ with state space $\cstates_i$ and transition matrix $P_i(x, y) = P(x, y)$ where $x \neq y \in \cstates_i$ (with the total remaining probability, the chain stays in the current state).
In addition, we define the chain $\mathcal{M'}$ with state space $\cstates'~=~[0, nb]$ and transition matrix $P'(i, j)~=~\sum_{x \in \cstates_i} \sum_{y \in \cstates_j} P(x, y)$ if $|i - j| = 1$ where $i, j \in \cstates'$ and where again, with the total remaining probability, the chain stays in the current state.

\begin{lemma}[Corollary 3.3 of~\cite{DBLP:journals/cpc/MartinR06}]
    \label{lem:mc-decomp}
    Let $\beta > 0$ and $\gamma > 0$ such that $P(x, y) \geq \beta$ for all $x, y \in \cstates$ where $P(x, y) > 0$, and $\pi(\delta_i(\cstates_j) \geq \gamma \pi(\cstates_i)$ for all $i \neq j$ where $P(i, j) > 0$ and $\delta_i(\cstates_j)$ is the subset of states in $\cstates_j$ where $P(i, j) > 0$.
    Then $\Gap(P) \geq \beta \gamma \Gap(P') \min_i \Gap(P_i)$.
\end{lemma}

\begin{lemma}[Proposition 6 of~\cite{GeomBounds}]
    \label{lem:conductance}
    For a MC with state space $\cstates$ and transition matrix $P$, define $h$ as $$
    h = \min_{\substack{X \subset \cstates \\ \pi(X) \leq {1}/{2}}}\frac{\sum_{x \in X}\sum_{y \in \cstates \setminus X} \pi(x) P(x,y)}{\pi(X)},
    $$ where $P(x, y)$ is the probability of moving from $x$ to $y$ and $\pi(X) = \sum_{x \in X}\pi(x)$.
    Then, $1 - 2h \leq \lambda_1 \leq 1 - h^2$.
\end{lemma}

\begin{proof}[Proof of \cref{thm:rapid-mixing}]
    By \Cref{lem:mc-decomp}, the result follows by showing sufficient lower bounds for $\beta, \gamma, \Gap(P')$ and $\min_i \Gap(P_i)$.
	
    We start with $\min_i \Gap(P_i)$.
    A generalized variant of this kind of chain called the load-exchange Markov chain has been analyzed in \cite{DBLP:conf/stacs/AmanatidisK23}.
    In fact, by combining \cite[Theorem 4.2]{DBLP:conf/stacs/AmanatidisK23} and \cite[Cor.~2.5]{DBLP:conf/stacs/AmanatidisK23}, it immediately follows that $\min_i \Gap(P_i) \geq 1 / (n^3 (b - a) 2)$.
    
    To bound $\Gap(P')$, we use \Cref{lem:conductance}.
    Consider any adversary set of states $X \subset \cstates'$ as required for \Cref{lem:conductance}.
    Observe that if $i \in X$ is a state such that $P'(i,j) > 0$ for some $j \notin X$, then $P'(i,j) \geq 1 / 8 n$.
    In addition, for any $i$, $\pi(i)$ is proportional to the number of weights on the $n$-cycle which sum to $i$.
    Precisely, this number is given by the polynomial coefficient   $\binom{n}{i}_{b - a + 1}$, see for example~\cite{AdvComb, UniformDist}.
    For our purposes, it suffices to observe that $\pi(i)$ has a peak around some value $i$, and monotonically decreases in both directions.
    Now, let $i^*$ be the state in $X$ such that $\pi(i^*)$ is maximal, and assume that the only state $i$ such that $P'(i,j) > 0$ for some $j \notin X$ is a state $i < i^*$ (the other cases all result in better bounds or are symmetric).
    Then it holds that
    $\pi(0) \leq \pi(1) \leq \dots \leq \pi(i) \leq \dots \leq \pi(i^*)$.
    Moreover, \Cref{lem:conductance} requires $\pi(0) + \pi(1) + \dots + \pi(i - 1) \geq 1 / 2$, and thus $\pi(i) \geq 1 / 2 nb$ and $\pi(i) / \pi(X) \geq 1 / nb$.
    Combining this estimate with the bound on $P'(i, j)$ then gives $\Gap(P') = 1 - \lambda_1' \geq h^2 \geq 1 / 64 n^4 b^2$.
	
    Finally, observe that $\beta \geq 1 / 4 n^2$ and $\gamma \geq 1 / n$, which concludes the proof.
\end{proof}

